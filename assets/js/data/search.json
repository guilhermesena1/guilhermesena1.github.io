[ { "title": "Wavefront alignments pt 1 : The Myers edit distance algorithm", "url": "/posts/wavefront-pt-1/", "categories": "C++, alignment-algorithms", "tags": "", "date": "2022-07-22 00:00:00 +0000", "snippet": "This is the first part of a two-part post that explains the wavefrontalignmentalgorithm,a 2020 paper that finds the alignment between two sequences $A$ and $B$in $O((|A| + |B|)s)$, where $s$ is the alignment “distance”. Weare using “distance” instead of “score” because these algorithms onlymake sense when the match score is 0 and the mismatch, indel andpossibly gap-open scores are non-negative.In this first post, we will discuss thealgorithmintroduced by Prof. Gene Myers in 1986. This algorithm is also thebasis of the diff tool in Linux, used to find the differencesbetween two files. I think this says volumes about the algorithm’srelevance. Personally I can only dream of writing an algorithm thatwill be adopted by a GNU tool.MotivationMany fields in computational biology revolve around findingsimilarities and differences between extremely large sequences. Inmost cases, these differences are formalized through approximatestring matching problem formulations.Localandglobalalignments are ubiquitous, so a lot of interest exists in creatingefficient implementations of alignment algorithms.The Needleman-Wunsch and Smith-Waterman alignment algorithms are theonly ones guaranteed to find optimal global and local alignment,respectively, of sequences $A$ and $B$ for arbitrary scoring schemes.They are also $\\Theta(|A| |B|)$, meaning that, whether $A$ and $B$ arevery similar or very different, the number of operations is the same:We have to fill out the entire traceback matrix to find our answer,either as the score at the bottom-right element in the matrix (globalalignment) or the maximum element in the matrix (local alignment).In most applications in molecular biology, however, we only reach thepoint of aligning two sequences when there is already some evidencethat the two sequences are likely to be similar. This is eitherbecause we have prior knowledge of their similarity or because, priorto comparison, we “filtered” a set of candidate sequences for whichthere is some evidence of similarity. For example, in sequencedatabase search algorithms such asBLASTor Kraken,we use smaller subsequence in our query (called “seeds”) and onlyfully compare our sequence to “hits” in the database that match theselected subsequence exactly. This means that the hits already have,by definition, a significant similarity to the sequence. The sameprocedure of “seeding” is done to map short sequences to a referencegenome in mapping algorithms like minimap2,abismal and literally every othermapping tool ever written in the last 5 years or so.For both the purposes of database search and read mapping (which insome sense is also a database search), we want two types of alignmentfunctions. The first type is a “fast” function that only computes thealignment score and nothing else. We want these to perform as fast aspossible, and it is in our interest to minimize the number ofoperations to obtain the score, after all we are only interested inwhichever sequence attains the highest score until we actually have toreport how the query and the best matching sequence differ. The second“slow” function computes both the score and the exact operations (substitutions,insertions and deletions) that are necessary to transform our query toour best match. This information is used downstream to study howthey differ, but we only call this function to the highest scoringcandidate among all our hits.It is very easy to verify (seeappendix) that mostof the run time for read mapping algorithms is spent on alignmentalgorithms to fully compare reads to hits (about 60-65% of the timefrom the mappers we tested). In fact, we can even see that the mosttime-consuming step are alignments that do not compute thetraceback, in other words, the false-positive alignments. We willtherefore focus on alignment algorithms that perform well for highlysimilar sequences. We will begin with what is possibly the simplestform of alignment of all: the edit distance.Edit distance problem formulationThe edit distance $D(A, B)$ between strings $A$ and $B$ is thenumber of substitutions, deletions and insertions of characters in $A$to make it identical to $B$. Obviously edit distance is a symmetric,that is, $D(A,B) = D(B,A)$. In fact, edit distance is a metric (canyou think of a proof for the triangle inequality?). Similar toalignments, edit distances can be computed in $O(|A| |B|)$ time. Let$A = a_1, \\dots a_m$ and $B = b_1, \\dots, b_n$ be two strings and forstring $S$, $S[i]$ denote the prefix of $S$ with the first $i$characters, with $S[0]$ being the empty string, then the edit distance$D[i, j]$ of prefix $A[i]$ with prefix $B[j]$ is given by $D[i, 0] =i$, $D[0, j] = j$ and $D[i, j] = D[i - 1, j - 1]$ if $A[i] = B[j]$,or $D[i, j] = 1 + \\mathrm{min}(D[i - 1, j - 1], D[i - 1, j],D[i, j-1])$ otherwise. Those who have seen the Smith-Watermanrecursionshould find this recursion familiar, with the exception that we alwaysuse $D[i-1, j-1]$ if there is a match, but sometimes we also takediagonals for substitutions of characters.A quick note on our definition of edit distance:In the next section we will describe an algorithm to compute editdistance based on the paper by Prof. Gene Myers. In the original 1986formulation, he described that the longest common subsequence and theshortest edit distance are dual problems. This is only true if theonly possible you allow are insertions and deletions. Here we are alsoconsidering substitutions to be a single edit, which makes ourupcoming description of the algorithm a bit different to his. Forexample, Myers would consider the edit distance of strings ABA andAAA to be 2 (delete B and insert A), whereas we consider it tobe 1 (substitute B with A).The Myers algorithm for edit distance calculationIf we are simply interested in the edit distance between $A$ and $B$,we only care about the value $D[m, n]$. In the recursion above, notethat we always take the diagonal when $A[i] = B[j]$. In other words,the traceback of $D[m, n]$ is composed of vertical lines, horizontallines, and a series of diagonals where there are huge runs of matchesbetween substrings of $A$ and $B$. We can take advantage of theselarge diagonals if we rethink the edit distance problem appropriately.From the Myers paper: “In practical situations, it is usually the parameter $d$ that is small.Programmers wish to know how they have altered a text file. Biologistswish to know how one DNA stand has mutated into another.”The idea of the Myers algorithm is to take advantage of these runs ofdiagonals by parametrizing the problem not by the prefix of the twostrings, but by the diagonals of the edit distance matrix $D$. First,we denote $m + n - 1$ diagonals of the matrix by how far off they arefrom the main diagonal, so $k = 0$ is the main diagonal, $k = 1$ isone diagonal below the main, and $k = -1$ is one diagonal to the rightof the main. In other words, the cells in diagonal $k$ are the cells$(x, y)$ where $x - y = k$.We will show that, with this parametrization, we can find the editdistance of $A$ and $B$ in $\\Theta((m + n) d)$, where $m$ is thelength of $A$, $n$ is the length of $B$ and $d$ is the edit distancebetween $A$ and $B$. This is much faster than the traditional $\\Theta (mn)$when $A$ and $B$ are expected to be similar, and not asymptoticallydifferent when that is the case since $d \\leq \\mathrm{max}(m, n)$ whensubstitutions only count as one edit and $d \\leq m + n$ when we onlyallow insertions and deletions (the Myers definition).The furthest-reaching point of diagonalsFor diagonal $k$, let $V[d, k]$ be the furthest reaching point fromthe origin of diagonal $k$ when we are allowed $d$ non-diagonalchanges (e.g. only insertions and deletions). In other words, $V$ is apair of coordinates $(x, y)$ where $x$ (or $y$) is maximum and $(x, y)$ canbe reached from $(k, 0)$ (if $k \\geq 0)$ or $(0, -k)$ (if $k &lt; 0$)with $d$ edits. Then the edit distance of $A$ and $B$ is the minimumvalue of $d$ for which $V[d, k] = (m, n)$ for some $k$.The key idea for the algorithm is that, for any diagonal the furthestreaching point with $d$ edits can be constructed easily from thefurthest reaching points with $d - 1$ edits. First, if $d = 0$, $V[0,k]$ is found by the largest series of matches between either thesuffix of $A$ starting at $k$ and $B$ or the suffix of $B$ starting at$k$ and $A$ (depending on the sign of $k$). For $d &gt; 0$, we canproceed as follows. Start with the furthest reaching points of$V[d-1, k-1]$, $V[d-1, k]$ and $V[d-1, k+1]$, both of which are onecell away from the diagonal $k$. Then we have a starting point at $k$either by going one cell to the left, one cell down, or one diagonalcell from these two points, since these will increment one extra editto get to diagonal $k$. Pick whichever of the two is furthest indiagonal $k$ to the origin, then go down diagonal $k$ on the series ofmatches between $A$ and $B$ until the first mismatch is found. When wefind the point $(m, n)$ as the furthest reaching point for some pair$(d, k)$, the edit distance is $d$.The algorithm takes $O((m+n)d)$ time and, if we are only interestedin $d$, it takes $O(m+n)$ space. For $0 \\leq d’ \\leq d$ (i.e. allpossible edit distances until our answer), we compute the furthestreaching point when we are allowed $d’$ edits. When $d’ = d$, we reachthe endpoint $(m, n)$ and stop.An short implementation of the algorithmHere is a C++ program that computes the edit distance betweentwo strings passed on two lines of STDIN. The edit_distance functionimplemented below also takes a third parameter MAX_D, and stopstrying to compute the edit distance if the answer goes above MAX_D.This has useful applications in the problems we stated above. Forexample, in read mapping, we will compare read to many sequences inthe reference genome to which we are mapping the reads. In the seedingstep, many of the retrieved sequences are false positives, and we wantto stop comparing as soon as we realize that we will not get asatisfactory answer. This is normally done by setting a maximumacceptable number of edits, which we can use to accelerate ourcomparison.A quick note about this code, which is easier to visualize with penand paper: Suppose you are at diagonal k and your horizontal offsetto the start of the diagonal is x. If you go one cell below todiagonal k+1 your horizontal offset to this new diagonal is x+1.However, if you go one cell to the right to diagonal k-1, youroffset at this new diagonal will still be x. Finally, if you godiagonally at diagonal k, you are still at diagonal k, but yourhorizontal offset is now x+1. This is the rational for lines 30 to38 in the code below. The last thing to mention is that we do not needto keep a pair (x, y) as the furthest reaching point for diagonalk. If we know x, then y = x - k, so everything is parametrizedby the horizontal offset x.#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;using std::string;using std::vector;using std::cin;using std::cout;using std::endl;// we can use std::max from algorithm too, but this is fasterinline uint32_tmax32(const uint32_t a, const uint32_t b) { return (a&gt;b) ? a: b; }// edit distance function that stop if the distance is &gt; MAX_Duint32_tedit_distance(const string &amp;a, const string &amp;b, const uint32_t MAX_D) { const uint32_t n = a.size(); const uint32_t m = b.size(); vector&lt;uint32_t&gt; V(2*MAX_D + 1, 0); vector&lt;uint32_t&gt; Vp(2*MAX_D + 1, 0); int32_t k = 0; uint32_t x = 0, y = 0; for (int32_t D = 0; D &lt;= static_cast&lt;int32_t&gt;(MAX_D); ++D) { for (k = -D; k &lt;= D; ++k) { // from the diagonal: increment one position x = (D == 0) ? 0 : Vp[MAX_D + k] + 1; // from above: we are also one point farther from // the diagonal above us when we move one position down x = (k == -D) ? x : max32(x, Vp[MAX_D + k - 1] + 1); // from the left: we are at the same diagonal position x = (k == D) ? x : max32(x, Vp[MAX_D + k + 1]); // extend the reaching point with run of matches for (y = x - k; x &lt; n &amp;&amp; y &lt; m &amp;&amp; a[x] == b[y]; ++x, ++y); if (x == n &amp;&amp; y == m) return D; V[MAX_D + k] = x; } // copies the 2*D answers we found to use it in the next iteration if (D != static_cast&lt;int32_t&gt;(MAX_D)) copy(begin(V) + MAX_D - D, begin(V) + MAX_D + D + 1, begin(Vp) + MAX_D - D); } // edit distance &gt; MAX, reject comparison. return MAX_D + 1;}// general-purpose edit distance. If MAX_D not defined, then// we use the maximum, which is |A| + |B|uint32_t edit_distance(const string &amp;a, const string &amp;b) { return edit_distance(a.size() &gt; b.size() ? a : b, a.size() &gt; b.size() ? b: a, max32(a.size(), b.size()));}int main(int argc, const char **argv) { string a, b; cin &gt;&gt; a &gt;&gt; b; cout &lt;&lt; \"edit distance: \" &lt;&lt; edit_distance(a, b) &lt;&lt; endl; return EXIT_SUCCESS;}Benchmarking the algorithmI ran the edit distance calculation to find the difference betweenthe human chromosome X in the human genome versions 37 (hg19) and 38(hg38). For simplicity, I compared the first 1M characters of the twoassemblies, then the first 10M characters. I also removed all Ns fromboth assemblies and converted letters to uppercase prior tocomparison.This is the result for the first 1M characters:$ /usr/bin/time -v ./wavefront &lt;in-1m.txtedit distance: 101430 Command being timed: \"./wavefront\" Elapsed (wall clock) time (h:mm:ss or m:ss): 0:55.59 Maximum resident set size (kbytes): 36512 Exit status: 0And this is the result for the first 10M characters:$ /usr/bin/time -v ./wavefront &lt;in-10m.txtedit distance: 285326 Command being timed: \"./wavefront\" Elapsed (wall clock) time (h:mm:ss or m:ss): 7:55.84 Maximum resident set size (kbytes): 335364 Exit status: 0The difference is a bit steep. We have 10% on the first 1M charactersthen less than 3% for 1M characters. Let us do 40M characters now!edit distance: 330050 Command being timed: \"./wavefront\" Elapsed (wall clock) time (h:mm:ss or m:ss): 10:53.26 Maximum resident set size (kbytes): 1331500 Exit status: 0Looks like it’s less than 1% now! The more we compare, the moresimilar they become (though the number of edits is still increasing,which is encouraging to confirm that the algorithm is working).Do note that 40M reads would require $\\approx 10^{15}$ operations inthe traditional edit distance algorithm proposed in the start of thispost, so we made good progress for similar sequences apparently :)In the next post we will extend this idea of “furthest reaching point”to affine local alignments to fully describe and implement thebeautiful algorithm shown by Marco-Sola and colleagues!Appendix: The time mappers spend aligning readsTo measure the alignment time, I took one million reads in a FASTQfile and ran both minimap2 andabismal to map them tohg38 (it doesn’t matter much how much error reads have, as long asit’s uniformly sampled from the genome). Using perf record &lt;command&gt;,we can store the time spent on each function in theprogram on a summary file, then the perf report reads the file andsorts the programfunctions by time spent, finally summarizes it to us on screen.It is an amazing profiling tool!For minimap2, here is the result:For abismal, here is the result: In minimap2, we can see that 36.86% of the time is spent at functionksw_extd2_sse41. This is the beautiful SSE implementation ofSmith-Waterman in the mapper, which we will cover in more detail inanother post. In abismal we have 33.67% of the time onprocess_seeds and 16.32% of the time on AbismalAlign. Theprocess_seeds step compares reads to hits using only Hammingdistance, and the AbismalAlign::align&lt;false&gt; function is the bandedSmith-Waterman algorithm (the “false” in the template means to onlycalculate score, not traceback/CIGAR string).In both cases, we can see that the bulk of time is not in collectingseeds, finding them in the genome, ecoding or any other secondaryoperation. Instead, the alignment itself comprises the majority of themapping effort, which greatly motivates fast implementations of thealgorithms we have available today." }, { "title": "The most naive phylogenetic reconstruction algorithm", "url": "/posts/possibly-the-most-naive-phylogenetic-reconstruction-algorithm/", "categories": "C++, phylogenetics", "tags": "", "date": "2022-07-18 00:00:00 +0000", "snippet": "The full source code for this post can be found onGitHub.This post was motivated by the following question: what would be thesimplest problem we could formulate to introduce a computer sciencestudent to the field of bioinformatics? This is the answer I came upwith, and is a (hopefully) fun attempt to analyze easily accessiblebiological data with very little code or effort. The question we willaddress is the following:given the genome sequences of a set of species, can we reconstructtheir speciation history?Below we will provide a brief introduction to the problem, thenformulate it more formally and solve it with some code, after which wewill discuss the code’s correctness, efficiency and potentiallimitations.IntroductionTwo species that are phenotypically very similar are expected to havehad a recent common ancestor. In other words, not too long ago (whichin “evolution time” may mean hundreds of thousands of years ago), aspeciation event occurred, and the two resulting species evolvedindependently, resulting in the observable differences. The longer agothe speciation event, the more different species are today.In theory we can (and have) reconstruct speciation events by observingphysical traits (phenotypes) of a pair of species. For example, we donot need to look at DNA to have a strong conviction that the Chinesehamster and the mouse are close siblings evolutionarily. Just look atthem! (and take a second to appreciate how adorable they are)Conversely, relying purely on traits can be misleading. Bats and birdshave wings and other similar physical traits, but bats are moreclosely related to cats than to birds. Similarly, mammalian aquaticanimals like whales and dolphins are closer to wolves and alpacas thanto fish (by “closer” I mean that the speciation event of the mostrecent common ancestor occurred more recently). These are examples ofconvergentevolution, wheretwo species have similar traits not necessarily because they arerelated by recent common ancestry, but because they are under similarselective pressure to acquire those traits.With recent genome sequencing technologies, we can objectively measuresimilarity between two species: simply measure the “similarity”between the genome sequences, where the sequences are strings ofcharacters (A, C, G, T) representing chromosomes. This is easier saidthan done. First, we need to define what “similarity” of sequencesmeans. When speciation occurs, independent genome divergence occursthrough a sequence of transformations: mutations, nucleotideinsertions, deletions, duplications of certain sequences, and possibletranslocations and inversions of large portions of the genome. Simplyput, pieces of DNA can move around, mutate, copy-paste themselves, andother small operations that can significantly change the resultingsequence. Can you think of a similarity metric between two stringsthat would identify similar genomic sequences under these potentialchange operations? Think if edit distance would be enough. Yes? No? Tome at least it is not immediately obvious. Simple translocations ofgenome sequences can significantly change the edit distance.In most bioinformatics methods used today, comparison of sequences isdone through (possibly some modification of) the local alignment oftwosequences.Given sequences $A$ and $B$, of sizes $|A|$ and $|B|$, the localalignment of $A$ and $B$ is the most similar substring of $A$ to asubstring of $B$. Objectively, we devise a scoring scheme that rewardssimilar letters in $A$ and penalize letter differences, insertions anddeletions. The local alignment can be found through the Smith-Watermanalgorithm in $O(|A| |B|)$ by filling a $|A| \\times |B|$ matrix. Thelocal alignment score $S[i, j]$ of the first $i$ characters of $A$ andthe first $j$ characters of $B$ can be found by the following dynamicprogramming iteration: $S[i, 0] = S[0, j] = 0$ and for $i, j &gt; 0$:\\[S[i, j] =\\begin{cases}S[i - 1, j - 1] + s(A[i], B[j]) \\\\S[i - 1], j] - \\delta \\\\S[i, j - 1] - \\delta \\\\0\\end{cases}\\]where $s(x, y) = 1$ if $x = y$ or $-\\mu$ if $x \\neq y$. Here $\\mu$ isthe penalty of mismatch of two letters, and $\\delta$ is thepenalty to insert or delete a character in either $A$ or $B$.This is not a post about local alignments, so this extremely simpledefinition of local alignment will suffice for our purposes. We caneven assume $\\mu = \\delta = 1$, which is possibly the simplestalignment scheme. I should, however point out that the resulting scorematrix $S$ contains a lot of information about the evolutionaryrelationship between $A$ and $B$. The highest-scoring location in $S$is the most similar subsequence of the two, but other high-scoringcells in the matrix can potentially identify subsequences thattranslocated across the genome and diverged independently. Possibleinversions can be found by aligning $A$ to the reverse-complement of$B$ and vice-versa. By studying the alignment matrix, we can learn, ingreat detail, what likely happened to certain genome subsequences, andquantify how exactly they diverged between the two species.The limitation of alignments: Quantifying similarities betweenspecies through local alignments is not immediately obvious. Thehighest alignment score (which, recall, is the most similarsubsequence) may not be representative of the global similarity, andthis becomes more true when comparing more distant species. We can useother high scores to reconstruct the divergence of subsequences, butit is not entirely obvious how to combine high scores in the matrixinto one global metric of similarity between sequences. Furthermore,many genomes, including most mammalians, are billions of sequenceslong. A $O(|A| |B|)$ algorithm is prohibitive both in time and memory.My proposition to solve this problem is to take a step back and thinkabout the absolutely most naive way to compare two sequences: Considersmall sequences of length $k$ (for example, $k = 12$), which we willcall $k$-mers. What if we just counted $k$-mers in two sequences andcalculated the sum of squares of their differences? This is analogousto measuring the similarity of two books based on their wordfrequencies. Two dictionaries written by different people would bevery similar, and so would two math textbooks that would constantlyuse words like “function”, “variable”, “number”&lt; etc.Note: we are shifting our thought process from “similarity” -a numberthat is higher the more similar two sequences are - to “distance”. Adistance function between two strings is a function $d$ such that, forstrings $A$ and $B$, $d(A, B) = 0$ if and only if $A = B$, $d(A,B) =d(B,A)$ and for any three strings $A, B, C$, $d(A,B) \\leq d(A,C) +d(B,C)$. The edit distance is an example of a distance metric betweenstrings, and we can also prove that our $k$-mer distance also is,since our $k$-mer counts induces a $4^k$-dimensional vector for whichEuclidean geometry properties apply.This approach is not very rigorous, and it may not necessarily work,but it is a start when thinking of a complex problem. Take a second tothink about how this could break: Could two highly similar sequenceshave highly different $k$-mer counts? Conversely, could two verydifferent sequences have similar $k$-mer counts? If you cannotconvince yourself that it can break easily, then the approach may havesome merit.In fact, hopefully I will be able to show you that this extremely naiveapproach leads to somewhat satisfiable results. The take-home messageshould be that these simple approaches should often not be overlooked.By the way, this is the most basic example of an alignment-freegenome comparisonmethod.Alignment-free sequence comparison research a beautiful field in andof itself with various applications in metagenomics, virology andpopulation genetics.Problem formulationWe are given a set of $n$ species and their reference genome sequences$S_1, \\cdots, S_n$, which is the concatenation of all of theirchromosomes. We wish to obtain the following. A $n \\times n$ distance matrix between all pairs of species A phylogenetic tree reconstructing the ancestral speciation eventsthat led to the observed species, based on the similarity matrix.For this post, we will use the following species: human, gorilla, mouse,Chinese hamster, cat, alpaca and whale. Quick pause for some moreadorable pictures.Genomes of each species are given as FASTAfiles. Those arehuman-readable text files, where lines indicating chromosome namesstart with the &gt; character (e.g. &gt;chr1), and below each such linewe see the genome sequence, with some line breaks after at most 80characters (so the sequence can be read in a terminal). For example,below are the first lines of the cat genome (felCat9.fa):$ head genomes/felCat9.fa&gt;chrA1atcaggagatctagatgcctggagaggagtggagaaaacgggaaaccctcttATGggaagaggtaatatgtatttctccttcgaatataaaaaaagtaaaaagaaggaaaacttaccaaattcacttatgagccattcattaccctgataccaaaaccagataaagccctccactaaaaccaaaactgcagcggcgccttgtgggctcggtcggttttactgtccaactcttaatttcagattaggaaataatcttgcggtgcatgggttcaagtcccacgttggaccctgccatgacagtgtggggaatggctaggattctctctctccctgtctctctgcccctccctcacttttttgtactctaaggaaagaaataaacatttaaaaaaatgttgaaaattttttaaataaaactgcataccaatagccttgatgagtatgtatgccFor our problem, we will download some FASTA files, inflate them,count the k-mers and save the k-mer frequencies into a table, whichwill then be turned into a distance matrix and a phylogenetic tree inR.Obtaining the dataPut this in a text file and call it genome_urls.txt. These are theURLs for the FASTA files of our species.$ cat genome_urls.txthttps://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gzhttps://hgdownload.soe.ucsc.edu/goldenPath/gorGor6/bigZips/gorGor6.fa.gzhttps://hgdownload.soe.ucsc.edu/goldenPath/mm39/bigZips/mm39.fa.gzhttps://hgdownload.soe.ucsc.edu/goldenPath/criGriChoV2/bigZips/criGriChoV2.fa.gzhttps://hgdownload.soe.ucsc.edu/goldenPath/felCat9/bigZips/felCat9.fa.gzhttps://hgdownload.soe.ucsc.edu/goldenPath/vicPac2/bigZips/vicPac2.fa.gzhttps://hgdownload.soe.ucsc.edu/goldenPath/balAcu1/bigZips/balAcu1.fa.gzTo download everything, on the same directory of yourgenome_urls.txt, use wget on each line of the file. Then create agenomes directory, unzip all the .fa files and move them to thegenomes folder as shown below.for i in $(cat genome_urls.txt); do echo $i; wget ${i}; donegunzip *.fa.gz;mkdir genomesmv *.fa genomesNow that we have the FASTA files, we will read them in C++ and createa $k$-mer frequency matrix.The C++ codeLet us first write a struct that will store $k$-mer frequencies for agenome. We will use $k = 12$, and pre-allocate counts for all $4^{12}$possible $k$-mers. We will assume counts fit into a 32-bit integer,since $2^{32}$ is larger than any of the genomes we are using.struct KmerStats { KmerStats() { kmer_count = vector&lt;uint32_t&gt;(num_kmers, 0); } void count_kmers(const string &amp;chrom); vector&lt;uint32_t&gt; kmer_count; static const uint32_t kmer_size = 12; static const uint32_t num_kmers = (2 &lt;&lt; (2*kmer_size));};The function count_kmers takes a chromosome and increments thevector kmer_count. We will encode $k$-mers as 24-bit numbers, with 2bits per letter. Here we have 00 = A, 01 = C, 10 = G, and 11 =T, so the number 0b110011001010010100011011 is the sequenceTATAGGCCACGT.Here is the implementation of count_kmers:voidKmerStats::count_kmers(const string &amp;chrom) { uint32_t mer = 0; auto itr(begin(chrom)); const auto lim(end(chrom)); for (size_t i = 0; itr != lim &amp;&amp; i &lt; kmer_size - 1; ++i, ++itr) shift_hash_key(*itr, mer); for (; itr != lim; ++itr) { shift_hash_key(*itr, mer); ++kmer_count[mer]; }}The function shift_hash_key simply shifts a k-mer two bits, appendsa new letter to the end of it, then discards the first number byapplying an AND (&amp;) operation to the number0b111111111111111111111111 (twenty-four 1s), which is 1 &lt;&lt;(2*KmerStats::kmer_size) - 1.inline voidshift_hash_key(const uint8_t c, uint32_t &amp;mer) { static const uint32_t hash_mask = KmerStats::num_kmers - 1; mer = ((mer &lt;&lt; 2) | encode_char[c]) &amp; hash_mask;}Finally, we write a function to take a file name, open it, read thechromosomes and process them onto a KmerStats object. Here we use apre-allocation size of 250 million for the chrom string, which islarger than the largest chromosome we expect. This allows us to re-usememory each time we read a chromosome.voidprocess_species(const string &amp;file, KmerStats &amp;v) { // get file size ifstream in(file); if (!in) throw runtime_error(\"cannot open file \" + file); static const size_t RESERVE_SIZE = 250000000; string chrom; chrom.reserve(RESERVE_SIZE); string line; while (getline(in, line)) { if (line[0] != '&gt;') copy(begin(line), end(line), back_inserter(chrom)); else process_chrom(chrom, v); } process_chrom(chrom, v); // last chromosome after EOF in.close();}The process_chrom function simply encodes the string in two bits perletter, replacing any non-ACGT character to a random character amongthe two. This ensures that, when counting $k$-mers, we only see ACGTsin our chromosome.inline voidprocess_chrom(string &amp;chrom, KmerStats &amp;v) { // makes sure letters are only ACGT: for (auto it(begin(chrom)); it != end(chrom); ++it) *it = ((encode_char[static_cast&lt;uint8_t&gt;(*it)] == 4) ? \"ACGT\"[rand()%4] : *it); v.count_kmers(chrom); chrom.clear();}and the encode_char is a static look-up conversion between ASCIIcharacters and two-bit representations. We set 0 for the charactersa and A, 1 for c and C, 2 for g and G and 3 for t andT. The rest we set to 4, and if we read a character that is a 4 inour look-up, we replace with a nucleotide:static const uint8_t encode_char[256] = { 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, //4 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, //17 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, //33 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, //49 4, 0, 4, 1, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, //@,A-O 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, //P-Z 4, 0, 4, 1, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, //`,a-o 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, //p-z 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4};Finally, our main function takes two arguments, the first is a “fileof files”, which is a two-column file showing the species name in thefirst column and the path to its FASTA genome in the second. Forexample, this is a file called genomes.txt:$ cat genomes.txtchinese_hamster genomes/criGriChoV2.facat genomes/felCat9.fagorilla genomes/gorGor6.fahuman genomes/hg38.famouse genomes/mm39.faalpaca genomes/vicPac2.fawhale genomes/balAcu1.faAnd our main function simply reads this file and calls the functionswe created. When done, our output will be a table with $4^{12}$ rows and$n$ columns, where $n$ is the number of species. The element in rowi and column j is the frequency of $k$-mer i (as its binaryrepresentation) in species j. This is a data frame that we can readinto R:intmain(int argc, const char **argv) { if (argc != 2) { cout &lt;&lt; \"usage: ./phylo &lt;input-species.txt&gt;\" &lt;&lt; endl; return 0; } // ensures the k-mer size used fits in a 32-bit number static_assert(KmerStats::kmer_size &lt;= 16); vector&lt;string&gt; species; vector&lt;string&gt; files; string tmp1, tmp2; ifstream in(argv[1]); while (in &gt;&gt; tmp1 &gt;&gt; tmp2) { species.push_back(tmp1); files.push_back(tmp2); } in.close(); // print the headers: the species names, separated by tabs copy(begin(species), end(species), std::ostream_iterator&lt;string&gt;(cout, \"\\t\")); cout &lt;&lt; \"\\n\"; vector&lt;KmerStats&gt; v(species.size()); omp_set_num_threads(8); // comment if OpenMP not used#pragma omp parallel for for (size_t i = 0; i &lt; species.size(); ++i) {#ifdef VERBOSE#pragma omp critical { cerr &lt;&lt; \"processing \" &lt;&lt; species[i] &lt;&lt; \"...\\n\"; }#endif process_species(files[i], v[i]); }#ifdef VERBOSE cerr &lt;&lt; \"writing output\\n\";#endif const size_t num_species = species.size(); for (size_t i = 0; i &lt; KmerStats::num_kmers; ++i) { for (size_t j = 0; j &lt; num_species; ++j) printf(\"%d\\t\", v[j].kmer_count[i]); printf(\"\\n\"); } return EXIT_SUCCESS;}Compiling the codeWe will create a Makefile to compile the program. If you do not haveOpenMP you can remove the -fopenmp flag below and the code will runsingle-thread. It will use less memory and more time, but it shouldstill finish in a few minutes.all : phylophylo: src/phylo.cpp\tg++ -O3 -Wall -std=c++11 -o phylo src/phylo.cpp -fopenmpclean:\trm phyloWe can compile by simply runningmake alland run the program by writing./phylo genomes.txt &gt;kmer-counts.tsvProfiling the codeWe can further profile using /usr/bin/time (GNU time) to see howmuch time and memory it takes. Using 8 cores we get the following:$ /usr/bin/time -v ./phylo genomes.txt &gt;kmer-counts.tsvprocessing chinese_hamster...processing mouse...processing whale...processing gorilla...processing cat...processing alpaca...processing human...writing output Command being timed: \"./phylo genomes.txt\" User time (seconds): 525.60 System time (seconds): 17.25 Percent of CPU this job got: 524% Elapsed (wall clock) time (h:mm:ss or m:ss): 1:43.54 Average shared text size (kbytes): 0 Average unshared data size (kbytes): 0 Average stack size (kbytes): 0 Average total size (kbytes): 0 Maximum resident set size (kbytes): 1653768 Average resident set size (kbytes): 0 Major (requiring I/O) page faults: 0 Minor (reclaiming a frame) page faults: 412911 Voluntary context switches: 659062 Involuntary context switches: 91400 Swaps: 0 File system inputs: 0 File system outputs: 805360 Socket messages sent: 0 Socket messages received: 0 Signals delivered: 0 Page size (bytes): 4096 Exit status: 0So we used a little under 2 minutes and 1.6 GB to create our table. Notethat the high memory use is because we used OpenMP to count the k-mersof all 7 species in parallel, so all KmerStats objects were loaded.Each KmerStats object allocates a vector of size $4^{12}$ with 32bits, so each takes 64 MB. Then each thread uses an additional 250 MBas pre-allocation for the chromosomes.We can further profile the code usingperf.perf record -v ./phylo genomes.txt &gt;kmer-counts.tsvperf reportThe R codeFor the final part, we will construct a hierarchical clustering basedon the $n \\times n$ distance matrix, defined as the sum of squares ofthe differences between $k$-mer frequencies for any two species. Wewill load the output of the C++ program into a matrix x, calculatethe pairwise distances using the dist function (we need to transposebecause dist is between all pairs of rows), then use heatmap andhclust to make plots.&gt; x &lt;- read.table('kmer-counts.tsv', header = T, row.names=NULL)&gt; the.dist &lt;- dist(t(x)) # distance between all pairs of species&gt; heatmap(the.dist) # heatmap of distance matrix&gt; plot(hclust(the.dist), hang = -1) # phylogenetic treeThis is the heatmap result:And this is the resulting treeIf you compare where the species lie in the UCSC genome browsertree, you will see thatour tree is consistent with theirs. Human and gorilla clustertogether, as do mouse and hamster. Whale, cat and alpaca clustertogether, with whale closer to alpaca. Hooray!Limitations of the methodThis algorithm is admittedly naive. First, it treats the $k$-merfrequencies in isolation. We have not accounted for co-occurences of$k$-mers. Consider the $k$-mer AAAAAAAAAAAA and three genomes. Ingenomes A and B, we have a large run of 1000 consecutive A, resultingin 989 occurrences of this $k$-mer. Then, in genome C, the sequenceAAAAAAAAAAAA appears uniformly at random in the middle of largermore complex sequences. The contribution of AAAAAAAAAAAA isidentical in all three genomes, but the correlation of $k$-mers in Aand B implies that they are more similar. We can incorporateco-occurrences of sequences by modeling them as Markov chains, andcomparing the Markov chain parameters instead of the $k$-mersdirectly. There is certainly a lot to improvement avenues to explore,but our idea is a start.Follow-up questionsWe can use a similar approach to guess, given a sequencing dataset(e.g. Illumina, PacBio or Oxford Nanopore), which species it mostlikely comes from. Can you think about how to do this? Whatadjustments are required in this method?" }, { "title": "Setting up a blog", "url": "/posts/setting-up-a-blog/", "categories": "hello", "tags": "", "date": "2019-12-11 00:00:00 +0000", "snippet": "I am configuring this blog if I want to communicate, write or document thingsusing markdown and figures. This post is to test if I can write some code withsyntax highlight and some math.Here’s an example c++ code:// hi.cpp#include &lt;iostream&gt;intmain(int argc, const char **argv) { // prints hi to stdout std::cout &lt;&lt; \"Your program has \" &lt;&lt; argc &lt;&lt; \" arguments\" &lt;&lt; std::endl; return 0;}This is how to compile it:$ g++ -O3 -Wall -o hi hi.cppAnd this is how you run it$ ./hi arg1 arg2 arg3Your program has 4 argumentsThis is a path to a link, and below is an equation:\\[x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\\]" } ]
